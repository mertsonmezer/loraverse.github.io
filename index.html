<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>LoRAverse</title>

  <!-- Meta Tags for SEO and Social Sharing -->
  <meta name="description" content="LoRAverse: A Submodular Framework to Retrieve Diverse Adapters for Diffusion Models - ICCV 2025">
  <meta property="og:title" content="LoRAverse">
  <meta property="og:description" content="A Submodular Framework to Retrieve Diverse Adapters for Diffusion Models">
  <meta property="og:image" content="images/teaser.jpg">

  <!-- External Stylesheets -->
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;500;700&display=swap">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">

  <!-- Custom Stylesheet -->
  <link rel="stylesheet" href="assets/style.css">
</head>

<body>
  <div class="container">
    <!-- Conference Badge -->
    <div class="conference-badge">
      <img src="images/logos/iccv25-logo.png" alt="ICCV 2025" class="conference-logo">
    </div>

    <!-- Title -->
    <div class="title">
      <h1><strong>LoRAverse</strong>: A Submodular Framework to Retrieve Diverse Adapters for Diffusion Models</h1>
    </div>

    <!-- Authors -->
    <div class="authors">
      <a href="#" target="_blank">Mert Sonmezer</a><sup>1</sup>,
      <a href="#" target="_blank">Matthew Zheng</a><sup>2</sup>,
      <a href="#" target="_blank">Pinar Yanardag</a><sup>2</sup>
    </div>

    <!-- Affiliations -->
    <div class="affiliations">
      <div class="affiliation">
        <sup>1</sup>
        <img src="images/logos/metu-logo.png" alt="METU Logo" class="affiliation-logo">
        Middle East Technical University
      </div>,
      <div class="affiliation">
        <sup>2</sup>
        <img src="images/logos/vt-logo.png" alt="Virginia Tech Logo" class="affiliation-logo">
        Virginia Tech
      </div>
    </div>

    <!-- Navigation Links -->
    <div class="links">
      <a href="#" target="_blank" rel="noopener noreferrer">
        <i class="fas fa-file-pdf"></i> Paper
      </a>
      <a href="#" target="_blank" rel="noopener noreferrer">
        <i class="ai ai-arxiv"></i> arXiv
      </a>
      <a href="#" target="_blank" rel="noopener noreferrer">
        <i class="fab fa-github"></i> Coming soon
      </a>
    </div>

    <!-- Teaser Figure -->
    <div class="teaser">
      <table>
        <tr>
          <td>
            <img src="images/teaser.jpg" alt="LoRAverse Overview - Submodular algorithm selecting diverse LoRA adapters">
          </td>
        </tr>
        <tr>
          <td class="caption">
            LoRAverse enhances image diversity by employing a submodular algorithm to select a diverse and representative set of
            LoRA adapters. This approach begins by clustering the adapters based on their semantic meanings. From these clusters,
            the algorithm selects models that not only maximize diversity but also maintain strong alignment with the user-provided
            prompt, ensuring both variety and relevance in the generated images.
          </td>
        </tr>
      </table>
    </div>

    <!-- Abstract Section -->
    <div class="section">
      <h2>Abstract</h2>
      <p>
        Low-rank Adaptation (LoRA) models have revolutionized the personalization of pre-trained diffusion models by enabling
        fine-tuning through low-rank, factorized weight matrices specifically optimized for attention layers. These models
        facilitate the generation of highly customized content across a variety of objects, individuals, and artistic styles
        without the need for extensive retraining. Despite the availability of over 100K LoRA adapters on platforms like
        Civit.ai, users often face challenges in navigating, selecting, and effectively utilizing the most suitable adapters due
        to their sheer volume, diversity, and lack of structured organization. This paper addresses the problem of selecting the
        most relevant and diverse LoRA models from this vast database by framing the task as a combinatorial optimization
        problem and proposing a novel submodular framework. Our quantitative and qualitative experiments demonstrate that our
        method generates diverse outputs across a wide range of domains.
      </p>
    </div>

    <!-- Method Section -->
    <div class="section">
      <h2>Method</h2>
      <div class="figure method-figure">
        <img src="images/architecture.jpg" alt="Architecture of LoRAverse showing concept extractor and submodular retriever">
        <p class="caption">
          <strong>Architecture of LoRAverse.</strong> LoRAverse composed of two main modules: concept extractor and submodular retriever. The
          concept extractor processes the user prompt to identify concepts (keywords). These concepts guide to the
          submodular retriever, which selects a diverse and relevant subset of LoRA adapters by clustering similar
          adapters per concept and applying submodular optimization. Additionally, a safety-checking mechanism is integrated to
          filter out adapters containing offensive or inappropriate content.
        </p>
      </div>
    </div>

    <!-- Quantitative Results Section -->
    <div class="section">
      <h2>Quantitative Results</h2>
      <div class="figure quantitative plain">
        <img src="images/quantitative_results.jpg" alt="Quantitative comparison showing diversity metrics" class="quantitative-img">
        <p class="caption">
          <strong>Quantitative Comparison (CFG=7).</strong> LoRAverse enhances the diversity of image sets across various metrics while maintaining comparable text-image alignment.
          The user study reports which method produced preferred outputs (US-P) by participants, and average rating of
          faithfulness (US-F) and diversity (US-D) of outputs on a scale of 1 to 5.
        </p>
      </div>
    </div>

    <!-- Qualitative Results Section -->
    <div class="section">
      <h2>Qualitative Results</h2>
      <div class="figure plain">
        <img src="images/qualitative_results.jpg" alt="Qualitative comparison showing diverse image generation">
        <p class="caption">
          <strong>Qualitative Comparison.</strong> LoRAverse demonstrates a higher diversity compared to image sets generated by Stylus and SD
          v1.5.
        </p>
      </div>
    </div>

    <!-- BibTeX Section -->
    <div class="section">
      <h2>BibTeX</h2>
      <div class="bibtex">
        <pre>@article{loraverse2025,
    title = {LoRAverse: A Submodular Framework to Retrieve Diverse Adapters for Diffusion Models},
    author = {Sonmezer, Mert and Zheng, Matthew and Yanardag, Pinar},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    year = {2025}
}</pre>
      </div>
    </div>
  </div>

  <!-- Footer -->
  <div class="footnote">
    <p class="template-credit">
      This webpage template was borrowed from <a href="https://nerfies.github.io/" target="_blank" rel="noopener noreferrer">Nerfies</a>.
    </p>
  </div>
</body>

</html>